{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'How to use computer vision to crop images'\n",
    "date: '2016-03-23'\n",
    "path: /faces-and-stuff/\n",
    "readNext: /python_oop/2-classes-and-members/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![washington](./Marc-Riboud-Washington-1967.jpg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem of cropping\n",
    "Cropping of images is often one of the last things to do before publishing an\n",
    "article. We have to finalise all images and text content before knowing how much\n",
    "space to use for each component and how it all fits together.\n",
    "h\n",
    "In digital publishing, the same images are often reused in a multitude of shapes\n",
    "and sizes for different channels. A typical blog post or news article will have\n",
    "a main article view. But in a responsive page layout, the images often will have\n",
    "different shapes on different screen sizes. With a website redesign, legacy\n",
    "content might also have to be converted to a new layout in bulk. That could\n",
    "involve a new shape for primary and supporting images. There's section front\n",
    "pages, search result pages, «related content»-teasers and social media previews.\n",
    "Many of these layouts require that images must be cropped into a specific shape.\n",
    "\n",
    "Even a human designer or editor is doing the image cropping manually, it can be\n",
    "difficult to know which parts of a photo to crop away and which parts to keep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An algorithm of aesthetics\n",
    "When there's a large set of images that must be cropped, it's sometimes\n",
    "unfeasible to manually decide how to best crop each individual photo. Instead we\n",
    "can use an automated process to classify images and determine which features and\n",
    "point of interest that is most important, and as a consequence, which sections\n",
    "of the image that are less interesting.\n",
    "\n",
    "In this article I'll show how we can use the open source OpenCV computer vision\n",
    "library and the Python programming language to analyze photos to automate image\n",
    "cropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Existing solutions\n",
    "    * cropping as a service\n",
    "        https://github.com/thumbor/thumbor\n",
    "    \n",
    "* What I want\n",
    "    * self-contained\n",
    "    * flexible\n",
    "    * tweakable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Open Source Computer Vision library\n",
    "OpenCV is a very large library of tools and algoritms for computer vision. It's\n",
    "written in C++ and has bindings for Java, C++ and Python. Like many other\n",
    "scientific packagages that are written by and for academics and scientist, the\n",
    "documentation and the apis can be somewhat hard to understand without the\n",
    "relevant academic background.\n",
    "\n",
    "Installing OpenCV is also much less straightforward than your typical python\n",
    "package. To use the latest version with python 3 support you have to install a\n",
    "lot of supporting libraries and configure and build OpenCV itself using cmake.\n",
    "There are also prebuilt versions available for some versions and operating\n",
    "systems. I found the [installation guides at pyimagesearch.com][install] very helpful when\n",
    "to get opencv3.0 and python3.5 bindings installed on ubuntu.\n",
    "\n",
    "The OpenCV library gives you a very large toolbox of algorithms for doing all\n",
    "sorts of computer vision, video and image analysis. In this article I'm just\n",
    "going to use two of them: The [ORB] keypoint detector and descriptor extractor and\n",
    "the [Viola-Jones] object detection framework (Haar Cascade Classifier).\n",
    "\n",
    "When reading the OpenCV documentation, you'll run into a lot of academic terms\n",
    "like \"Haar Cascade\" and acronyms such as BRIEF (Binary Robust Independent\n",
    "Elementary Features). All of these are described in various scientific papers,\n",
    "and to really undestand how the algorithms work takes a lot of effort. The good\n",
    "news is that you don't really have to understand how everything works to be able\n",
    "to actually use OpenCV. A good place to find beginner friendly tutorials is\n",
    "[pyimagesearch.com].\n",
    "\n",
    "[install]: http://www.pyimagesearch.com/2015/07/20/install-opencv-3-0-and-python-3-4-on-ubuntu/\n",
    "[Viola-Jones]: https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework\n",
    "[ORB]: https://en.wikipedia.org/wiki/ORB_(feature_descriptor)\n",
    "[pyimagesearch.com]: http://pyimagesearch.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Specific libraries:\n",
    "    * Haar-cascade classifiers\n",
    "    http://docs.opencv.org/3.1.0/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0\n",
    "    https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework\n",
    "    * ORB feature detection\n",
    "    https://en.wikipedia.org/wiki/ORB_(feature_descriptor)\n",
    "    http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_orb/py_orb.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with OpenCV in Jupyter\n",
    "Since OpenCV is a computer _vision_ library, you can play around with images and\n",
    "\n",
    "algorithms and get quick visual results. Algorithms such as Viola-Jones and ORB\n",
    "are optimized for speed so that they can be used for real time video. Thus they\n",
    "are can also process static images very fast.\n",
    "\n",
    "Whenever I want to learn a new python library, I  use [Jupyter\n",
    "notebooks] to do some exploratory programming. This is also a tool\n",
    "that is used a lot in academia and science, since it's very well suited for\n",
    "exploring data and sharing code.\n",
    "\n",
    "Jupyter can also be used to edit markdown. In fact this blog post is written in\n",
    "jupyter (you can see the source [here][source]).\n",
    "\n",
    "The apis and output data structures in OpenCV do not seem to follow any common\n",
    "structure, so for a python programmer it can be quite confusing to use. Since I\n",
    "want to use both Viola-Jones (`cv2.CascadeClassifier`) and ORB\n",
    "(`cv2.ORBClassifier`) to detect salient features or points of interest in images,\n",
    "I decided to write python wrapper classes and my own visualisation code to give\n",
    "them a more or less uniform interface.\n",
    "\n",
    "[source]: https://github.com/haakenlid/hken.no\n",
    "[Jupyter notebooks]: http://jupyter.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature detector interface \n",
    "\n",
    "We'll start by building a base class for our feature detectors. It will not perform any image analysis. It's just an example of the interface. That is: the methods, inputs and outputs that are used when we build the keypoint and face detector later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "We'll start by importing a utility function to display images in the jupyter notebook to show our sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./monkey-race.jpg\" width=800px />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import display\n",
    "display.show_image('./monkey-race.jpg')  # This will display the original jpg file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the function we'll use to prepare image files for image analyzis. The function reads an image file and optionally resamples it to a standard image size. This is useful for normalizing images to a standard size, as well as for performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2           # The opencv python bindings\n",
    "import numpy         # NumPy is the fundamental package for scientific computing with Python.\n",
    "import typing as tp  # Used for python 3.5 type annotations.\n",
    "\n",
    "# OpenCv represents all images as n-dimensional numpy arrays.\n",
    "# For clarity and convenience, we'll just call it \"CvImage\"\n",
    "CvImage = numpy.ndarray\n",
    "\n",
    "def opencv_image(filename: str, resize: int=0) -> CvImage:\n",
    "    \"\"\"Read image file to grayscale openCV int array.\n",
    "\n",
    "    The OpenCV algorithms works on a two dimensional\n",
    "    numpy array integers where 0 is black and 255 is\n",
    "    white. Color images will be converted to grayscale.\n",
    "    \"\"\"\n",
    "    cv_image = cv2.imread(filename)\n",
    "    if resize > 0:\n",
    "        w, h = cv_image.shape[1::-1]  # type: int, int\n",
    "        multiplier = (resize ** 2 / (w * h)) ** 0.5\n",
    "        dimensions = tuple(\n",
    "            int(round(d * multiplier)) for d in (w, h))\n",
    "        cv_image = cv2.resize(cv_image, dimensions)\n",
    "    return cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to convert our example image to a `numpy.ndarray`, and see what the resulting data structure looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[218,  97,  86, 170,  29,  53,  34],\n",
       "       [193, 127,  57,  33, 125,  25, 124],\n",
       "       [244, 157,  86,  22,  17, 194,  63],\n",
       "       [ 21,  18,   1,   7,  17,  12, 125],\n",
       "       [158, 163, 171, 159, 169, 160,  89]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = opencv_image('./monkey-race.jpg', 6)\n",
    "img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we prepare the image for a computer vision algorithm, we'll try to find the smallest input size that still gives us acceptable results. Shrinking the input image can save a lot of execution time, but at some point, downsampling will result in low quality output from the algorithms. In this case, there's not much useful data left from the original image.\n",
    "\n",
    "To demonstrate this, let's convert the array back to a image format that the web browser can display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png/;base64,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\" width=800px />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the array as an inline data url in png-format\n",
    "display.show_image(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output data\n",
    "We know what the input looks like, let's figure out what output data we expect from our feature detector. \n",
    "To make the output portable, we'll ultimately store and transmit it in json format. It will be an array of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is what the json data looks like. Conveniently it's also valid python code.\n",
    "data =  [\n",
    "  {\n",
    "    \"className\": \"keypoint one\",\n",
    "    \"x\": 0.305,\n",
    "    \"y\": 0.255,\n",
    "    \"width\": 0.291,\n",
    "    \"height\": 0.392,\n",
    "    \"weight\": 1.644\n",
    "  },\n",
    "  {\n",
    "    \"className\": \"keypoint two\",\n",
    "    \"x\": 0.273,\n",
    "    \"y\": 0.222,\n",
    "    \"width\": 0.086,\n",
    "    \"height\": 0.116,\n",
    "    \"weight\": 0.362\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each feature is represented as a rectangle in a coordinate system where (0, 0) is the upper left corner of the image and (1, 1) is the lower right corner of the image. This is convenient since we are going to use this data to render html and svg graphics.\n",
    "\n",
    "`className` is a string that will be used as a css class for the feature, so we can distinguish various types of features.\n",
    "\n",
    "`x` and `y` are the coordinates of the upper left corner of the feature\n",
    "\n",
    "`weight` is a quantity representing the relative importance or saliency of a given feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize these feature, we'll use reactjs and node to create a svg and html widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cropboxWrapper\" style=\"flex-direction:column;display:flex;\"><div class=\"masterImgWrapper infoParent\"><img class=\"masterImg\" src=\"./monkey-race.jpg\"/><div class=\"overlayWrapper\"><svg class=\"overlay inactive\" viewBox=\"0 0 1 1\" preserveAspectRatio=\"none\" height=\"100%\" width=\"100%\"><symbol id=\"profile-face\" viewBox=\"0 0 100 100\"><path d=\"m15.3 69.6c-2.7-1.8-10.1-3.3-7.91-7.2 2.91-5.2 9.11-11.9\n",
       "              8.21-17.5-4-24.2 10-39.8 33.9-39.9 24-.09 37.5 12.8 37.5 38.2 0\n",
       "              35.7-51.1 60.8-59.8 48.5-8.8-12.6-7.6-17.4-11.9-22.1z\"></path></symbol><symbol id=\"frontal-face\" viewBox=\"0 0 100 100\"><path d=\"m50 5c-12.8 0-25.8 7.73-30 16.9-4.19 9.17-.562 14.4-.768\n",
       "              29.3-.205 15 6.92 30 13.4 34.9 6.49 4.88 11.3 8.89 17.3 8.89 6.04\n",
       "              0 10.8-4.01 17.3-8.89 6.6-4.9 13.7-19.9 13.5-34.9-.2-14.9\n",
       "              3.5-20.1-.7-29.3s-17.2-16.9-30-16.9z\"></path></symbol><path class=\"outside\" fill-rule=\"evenodd\" d=\"M0, 0H1V1H0ZM0.273, 0.222V0.647H0.596V0.222Z\"></path><g class=\"inside\"><path class=\"box\" d=\"M0.273, 0.222V0.647H0.596V0.222Z\"></path><svg class=\"handles\" viewBox=\"0 0 1 1\" preserveAspectRatio=\"none\" height=\"0.42500000000000004\" width=\"0.32299999999999995\" x=\"0.273\" y=\"0.222\"><rect class=\"1000\" width=\"0.1\" height=\"1.1\" x=\"-0.05\" y=\"-0.05\" style=\"cursor:ew-resize;\"></rect><rect class=\"0100\" width=\"1.1\" height=\"0.1\" x=\"-0.05\" y=\"-0.05\" style=\"cursor:ns-resize;\"></rect><rect class=\"0010\" width=\"0.1\" height=\"1.1\" x=\"0.95\" y=\"-0.05\" style=\"cursor:ew-resize;\"></rect><rect class=\"0001\" width=\"1.1\" height=\"0.1\" x=\"-0.05\" y=\"0.95\" style=\"cursor:ns-resize;\"></rect><rect class=\"1100\" width=\"0.1\" height=\"0.1\" x=\"-0.05\" y=\"-0.05\" style=\"cursor:nw-resize;\"></rect><rect class=\"0110\" width=\"0.1\" height=\"0.1\" x=\"0.95\" y=\"-0.05\" style=\"cursor:ne-resize;\"></rect><rect class=\"0011\" width=\"0.1\" height=\"0.1\" x=\"0.95\" y=\"0.95\" style=\"cursor:se-resize;\"></rect><rect class=\"1001\" width=\"0.1\" height=\"0.1\" x=\"-0.05\" y=\"0.95\" style=\"cursor:sw-resize;\"></rect></svg></g><g class=\"centerPoint\"><ellipse class=\"handle\" style=\"opacity:0;\" cx=\"0.4505\" cy=\"0.451\" rx=\"0.05\" ry=\"0.06734006734006734\"></ellipse><path class=\"cross\" d=\"M0, 0.451H1M0.4505, 0V1\"></path></g><svg class=\"feature keypoint one\" preserveAspectRatio=\"none\" viewBox=\"0 0 2 2\" x=\"0.305\" y=\"0.255\" width=\"0.291\" height=\"0.392\"><text x=\"1\" y=\"0.08247422680412371\" text-anchor=\"middle\"><tspan class=\"className\" x=\"1\" dy=\"-0.16494845360824742\" style=\"font-size:0.13745704467353953px;\">className: keypoint one</tspan><tspan class=\"weight\" x=\"1\" dy=\"-0.16494845360824742\" style=\"font-size:0.13745704467353953px;\">weight: 1.644</tspan></text><g><circle r=\"1\" cx=\"1\" cy=\"1\" class=\"back\"></circle><circle r=\"1\" cx=\"1\" cy=\"1\" class=\"front\"></circle><path class=\"cross\" d=\"M0,1h0.9m0.2,0h0.9M1,0v0.9m0,0.2v0.9\" transform=\"rotate(45 1 1)\"></path></g></svg><svg class=\"feature keypoint two\" preserveAspectRatio=\"none\" viewBox=\"0 0 2 2\" x=\"0.273\" y=\"0.222\" width=\"0.086\" height=\"0.116\"><text x=\"1\" y=\"0.27906976744186046\" text-anchor=\"middle\"><tspan class=\"className\" x=\"1\" dy=\"-0.5581395348837209\" style=\"font-size:0.4651162790697675px;\">className: keypoint two</tspan><tspan class=\"weight\" x=\"1\" dy=\"-0.5581395348837209\" style=\"font-size:0.4651162790697675px;\">weight: 0.362</tspan></text><g><circle r=\"1\" cx=\"1\" cy=\"1\" class=\"back\"></circle><circle r=\"1\" cx=\"1\" cy=\"1\" class=\"front\"></circle><path class=\"cross\" d=\"M0,1h0.9m0.2,0h0.9M1,0v0.9m0,0.2v0.9\" transform=\"rotate(45 1 1)\"></path></g></svg></svg></div><div class=\"infoBoxWrapper\"><div class=\"infoBox\"><div class=\"infoRow\"><div class=\"label\">left:</div><div class=\"value\">0.222</div></div><div class=\"infoRow\"><div class=\"label\">top:</div><div class=\"value\">0.273</div></div><div class=\"infoRow\"><div class=\"label\">right:</div><div class=\"value\">0.647</div></div><div class=\"infoRow\"><div class=\"label\">bottom:</div><div class=\"value\">0.596</div></div><div class=\"infoRow\"><div class=\"label\">x:</div><div class=\"value\">0.451</div></div><div class=\"infoRow\"><div class=\"label\">y:</div><div class=\"value\">0.451</div></div></div></div></div><div class=\"previewPanel\" style=\"flex-direction:row;\"><div class=\"previewWrapper infoParent\" style=\"flex:1;\"><svg class=\"previewImg\" style=\"background-image:url(./monkey-race.jpg);background-position:40.3% 38.4%;background-repeat:no-repeat;background-size:309.6% auto;\" viewBox=\"0 0 1 1\"></svg><div class=\"infoBoxWrapper\"><div class=\"infoBox\"><div class=\"infoRow\"><div class=\"label\">position:</div><div class=\"value\">40.3% 38.4%</div></div><div class=\"infoRow\"><div class=\"label\">size:</div><div class=\"value\">309.6% auto</div></div><div class=\"infoRow\"><div class=\"label\">aspect ratio:</div><div class=\"value\">1</div></div></div></div></div><div class=\"previewWrapper infoParent\" style=\"flex:0.5;\"><svg class=\"previewImg\" style=\"background-image:url(./monkey-race.jpg);background-position:40.3% 0.0%;background-repeat:no-repeat;background-size:309.6% auto;\" viewBox=\"0 0 0.5 1\"></svg><div class=\"infoBoxWrapper\"><div class=\"infoBox\"><div class=\"infoRow\"><div class=\"label\">position:</div><div class=\"value\">40.3% 0.0%</div></div><div class=\"infoRow\"><div class=\"label\">size:</div><div class=\"value\">309.6% auto</div></div><div class=\"infoRow\"><div class=\"label\">aspect ratio:</div><div class=\"value\">0.5</div></div></div></div></div><div class=\"previewWrapper infoParent\" style=\"flex:2.5;\"><svg class=\"previewImg\" style=\"background-image:url(./monkey-race.jpg);background-position:19.0% 38.6%;background-repeat:no-repeat;background-size:126.8% auto;\" viewBox=\"0 0 2.5 1\"></svg><div class=\"infoBoxWrapper\"><div class=\"infoBox\"><div class=\"infoRow\"><div class=\"label\">position:</div><div class=\"value\">19.0% 38.6%</div></div><div class=\"infoRow\"><div class=\"label\">size:</div><div class=\"value\">126.8% auto</div></div><div class=\"infoRow\"><div class=\"label\">aspect ratio:</div><div class=\"value\">2.5</div></div></div></div></div></div></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.reactjs import render  \n",
    "from utils.cropengine import Feature\n",
    "# Renders the widget with react, redux and node.js\n",
    "features = [Feature.deserialize(d) for d in data]\n",
    "render('./monkey-race.jpg', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Feature` class is not very complicated, so I will not go through the source code in detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(top=0.255, right=0.596, className='keypoint one', weight=1.644, left=0.305, bottom=0.647)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1, f2 = features\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(utils.boundingbox.Box,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.__class__.__bases__  # Feature is a subclass of Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(top=0.222, right=0.596, bottom=0.647, left=0.273)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding two features together will give us a new Box that contains both features.\n",
    "f1 + f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(top=0.255, right=0.359, bottom=0.338, left=0.305)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The __and__ operator will return the intersection of the two features\n",
    "f1 & f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(top=0.353, right=0.52325, className='keypoint one', weight=0.822, left=0.37775000000000003, bottom=0.549)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication will change the size and weight of the Feature\n",
    "# but the center point and className will not change.\n",
    "f1 * 0.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* json output\n",
    "* react widget\n",
    "* discussion:\n",
    "    * How can I use this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Feature detector\n",
    "* What is ORB?\n",
    "* link to documentation\n",
    "* code\n",
    "* output\n",
    "* discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Face detection\n",
    "* What are Haas-cascades?\n",
    "* code\n",
    "* output\n",
    "* discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Combined feature detector\n",
    "* explanation\n",
    "* code \n",
    "* output\n",
    "* discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "hide": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.infoParent {\n",
       "  position: relative; }\n",
       "  .infoParent:hover .infoBox {\n",
       "    transform: translateY(0); }\n",
       "\n",
       ".infoBoxWrapper {\n",
       "  pointer-events: none;\n",
       "  overflow: hidden;\n",
       "  position: absolute;\n",
       "  bottom: 0;\n",
       "  left: 0;\n",
       "  right: 0;\n",
       "  z-index: 80; }\n",
       "  .infoBoxWrapper .infoBox {\n",
       "    display: block;\n",
       "    top: inherit;\n",
       "    transform: translateY(105%);\n",
       "    transition: transform 100ms ease;\n",
       "    background: rgba(0, 0, 0, 0.8);\n",
       "    font-size: 13px;\n",
       "    line-height: 1.2;\n",
       "    color: white;\n",
       "    padding: .3em;\n",
       "    margin: 0; }\n",
       "    .infoBoxWrapper .infoBox div {\n",
       "      display: inline-block; }\n",
       "    .infoBoxWrapper .infoBox .infoRow {\n",
       "      padding-right: 1em; }\n",
       "      .infoBoxWrapper .infoBox .infoRow .value {\n",
       "        font-weight: 500; }\n",
       "      .infoBoxWrapper .infoBox .infoRow .label {\n",
       "        padding-right: .2em; }\n",
       ".previewPanel {\n",
       "  display: flex;\n",
       "  flex: 3;\n",
       "  margin: -0.3vw;\n",
       "  padding: 0.6vw 0 0 0; }\n",
       "  .previewPanel .previewWrapper {\n",
       "    position: relative;\n",
       "    margin: 0.3vw; }\n",
       "    .previewPanel .previewWrapper svg.previewImg {\n",
       "      display: block; }\n",
       ".cropInfo {\n",
       "  top: 0;\n",
       "  left: 0;\n",
       "  position: absolute;\n",
       "  display: table; }\n",
       "  .cropInfo .infoRow {\n",
       "    display: table-row; }\n",
       "    .cropInfo .infoRow .label, .cropInfo .infoRow .value {\n",
       "      display: table-cell; }\n",
       "\n",
       "symbol {\n",
       "  overflow: visible; }\n",
       "\n",
       "@keyframes spin {\n",
       "  from {\n",
       "    transform: rotate(0deg); }\n",
       "  to {\n",
       "    transform: rotate(360deg); } }\n",
       "\n",
       ".overlayWrapper svg.overlay .feature {\n",
       "  shape-rendering: geometricPrecision;\n",
       "  overflow: visible;\n",
       "  transition: all 500ms; }\n",
       "  .overlayWrapper svg.overlay .feature text {\n",
       "    transition: inherit;\n",
       "    opacity: 0;\n",
       "    pointer-events: none; }\n",
       "    .overlayWrapper svg.overlay .feature text tspan {\n",
       "      fill: white;\n",
       "      vector-effect: non-scaling-stroke;\n",
       "      stroke: black;\n",
       "      stroke-opacity: 0.4;\n",
       "      stroke-width: 4;\n",
       "      font-weight: 500;\n",
       "      paint-order: stroke; }\n",
       "  .overlayWrapper svg.overlay .feature circle, .overlayWrapper svg.overlay .feature path, .overlayWrapper svg.overlay .feature rect, .overlayWrapper svg.overlay .feature use {\n",
       "    overflow: visible;\n",
       "    vector-effect: non-scaling-stroke;\n",
       "    fill: none;\n",
       "    stroke: white; }\n",
       "  .overlayWrapper svg.overlay .feature .front {\n",
       "    transition: all 300ms;\n",
       "    stroke-opacity: 0.8;\n",
       "    stroke-width: 1.2;\n",
       "    pointer-events: none; }\n",
       "  .overlayWrapper svg.overlay .feature .back {\n",
       "    stroke-opacity: 0.0;\n",
       "    stroke-width: 15;\n",
       "    pointer-events: stroke; }\n",
       "  .overlayWrapper svg.overlay .feature .cross {\n",
       "    transition: all 300ms;\n",
       "    pointer-events: none;\n",
       "    stroke-opacity: 0.0; }\n",
       "  .overlayWrapper svg.overlay .feature:hover .cross {\n",
       "    stroke-opacity: 1; }\n",
       "  .overlayWrapper svg.overlay .feature:hover .front {\n",
       "    stroke-opacity: 1;\n",
       "    stroke-width: 3; }\n",
       "  .overlayWrapper svg.overlay .feature:hover text {\n",
       "    opacity: 1; }\n",
       "\n",
       ".overlayWrapper .dragKing {\n",
       "  z-index: 100;\n",
       "  position: fixed;\n",
       "  top: 0;\n",
       "  left: 0;\n",
       "  right: 0;\n",
       "  bottom: 0;\n",
       "  cursor: move; }\n",
       "\n",
       ".overlayWrapper svg.overlay {\n",
       "  height: 100%;\n",
       "  z-index: 10;\n",
       "  shape-rendering: crispEdges;\n",
       "  position: absolute;\n",
       "  top: 0;\n",
       "  left: 0;\n",
       "  right: 0; }\n",
       "  .overlayWrapper svg.overlay path, .overlayWrapper svg.overlay rect, .overlayWrapper svg.overlay ellipse {\n",
       "    vector-effect: non-scaling-stroke;\n",
       "    fill: transparent; }\n",
       "  .overlayWrapper svg.overlay .outside {\n",
       "    fill: rgba(0, 0, 0, 0.5); }\n",
       "  .overlayWrapper svg.overlay .centerPoint {\n",
       "    position: relative; }\n",
       "    .overlayWrapper svg.overlay .centerPoint .handle {\n",
       "      cursor: crosshair;\n",
       "      opacity: 0; }\n",
       "      .overlayWrapper svg.overlay .centerPoint .handle:hover + .cross {\n",
       "        stroke: yellow; }\n",
       "    .overlayWrapper svg.overlay .centerPoint .cross {\n",
       "      pointer-events: none;\n",
       "      stroke: rgba(255, 255, 0, 0.5); }\n",
       "  .overlayWrapper svg.overlay .inside .box {\n",
       "    stroke: rgba(255, 255, 255, 0.3);\n",
       "    cursor: move; }\n",
       "  .overlayWrapper svg.overlay .inside:hover .box {\n",
       "    stroke: rgba(255, 255, 255, 0.8); }\n",
       "  .overlayWrapper svg.overlay .inside .handles {\n",
       "    overflow: visible; }\n",
       "  .overlayWrapper svg.overlay.inactive .inside, .overlayWrapper svg.overlay.inactive .handle {\n",
       "    pointer-events: none; }\n",
       ".cropboxWrapper {\n",
       "  max-width: 50em;\n",
       "  position: relative;\n",
       "  display: flex;\n",
       "  user-select: none;\n",
       "  -webkit-user-select: none;\n",
       "  margin: 1rem 0; }\n",
       "  .cropboxWrapper img {\n",
       "    display: block; }\n",
       "  .cropboxWrapper .masterImgWrapper {\n",
       "    flex: 11;\n",
       "    align-self: center; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import reactjs\n",
    "reactjs.css()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Summary\n",
    "* it's easy!\n",
    "* links\n",
    "    * OpenCV guy\n",
    "    * documentation\n",
    "    * sorl-thumbnail\n",
    "* My own stuff\n",
    "    * Algorithm\n",
    "    * React component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"className\": \"ORB keypoint\",\n",
      "    \"x\": 0.495,\n",
      "    \"y\": 0.235,\n",
      "    \"width\": 0.291,\n",
      "    \"height\": 0.392,\n",
      "    \"weight\": 1.644\n",
      "  },\n",
      "  {\n",
      "    \"className\": \"ORB keypoint\",\n",
      "    \"x\": 0.504,\n",
      "    \"y\": 0.379,\n",
      "    \"width\": 0.194,\n",
      "    \"height\": 0.262,\n",
      "    \"weight\": 1.267\n",
      "  },\n",
      "  {\n",
      "    \"className\": \"ORB keypoint\",\n",
      "    \"x\": 0.478,\n",
      "    \"y\": 0.427,\n",
      "    \"width\": 0.129,\n",
      "    \"height\": 0.174,\n",
      "    \"weight\": 0.789\n",
      "  },\n",
      "  {\n",
      "    \"className\": \"ORB keypoint\",\n",
      "    \"x\": 0.444,\n",
      "    \"y\": 0.186,\n",
      "    \"width\": 0.086,\n",
      "    \"height\": 0.116,\n",
      "    \"weight\": 0.385\n",
      "  },\n",
      "  {\n",
      "    \"className\": \"ORB keypoint\",\n",
      "    \"x\": 0.573,\n",
      "    \"y\": 0.442,\n",
      "    \"width\": 0.086,\n",
      "    \"height\": 0.116,\n",
      "    \"weight\": 0.362\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>./monkey-race.jpg</h2><p>detect: 15ms render: 427ms</p><IPython.core.display.HTML object>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import cropengine\n",
    "import json\n",
    "detector = cropengine.KeypointDetector(n=5)\n",
    "ff = detector.find_features('./monkey-race.jpg')\n",
    "data = json.dumps([f.serialize() for f in ff], indent=2)\n",
    "print(data)\n",
    "display.croppify_all(detector, ['./monkey-race.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
